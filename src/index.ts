import express, { Request, Response } from "express";
import cors from "cors";
import dotenv from "dotenv";
import multer from "multer";
import runLifeMdAgent from "./agent/index.js";
import { openai } from "./mcp/index.js";
import { toFile } from "openai/uploads";

interface AIRequestBody {
    message?: string;
}

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json());

const upload = multer({ storage: multer.memoryStorage() });

app.post("/api/ai", async (
    req: Request<unknown, unknown, AIRequestBody>,
    res: Response
) => {
    try {
        const { message } = req.body ?? {};
        if (typeof message !== "string" || message.trim().length === 0) {
            return res.status(400).json({ error: "message is required" });
        }

        const answer = await runLifeMdAgent(message);

        res.json({ answer });
    } catch (err) {
        console.error("AI error:", err);
        res.status(500).json({ error: "AI error" });
    }
});

// ðŸ”¹ ÐÐ¾Ð²Ð¸Ð¹ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¸Ð¹ ÐµÐ½Ð´Ð¿Ð¾Ñ–Ð½Ñ‚
app.post("/api/voice", upload.single("audio"), async (req, res) => {
    try {
        const file = req.file;

        if (!file) {
            return res.status(400).json({ error: "audio file is required" });
        }

        // 1) ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ”Ð¼Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ñ–ÑŽ Ð²Ñ–Ð´ OpenAI
        // ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¼Ð¾Ð¶Ðµ Ð±ÑƒÑ‚Ð¸ Ñ‚Ð¸Ð¿Ñƒ "gpt-4o-mini-transcribe" Ð°Ð±Ð¾ "whisper-1" â€“ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ñ‚Ð¾Ð³Ð¾, Ñ‰Ð¾ Ñƒ Ð²Ð°Ñ Ð´Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð¾.
        const audioFile = await toFile(file.buffer, file.originalname || "audio.webm");

        const transcription = await openai.audio.transcriptions.create({
            // ÑÐºÑ‰Ð¾ Ñƒ Ð²Ð°Ñ Ñ‰Ðµ whisper:
            model: "gpt-4o-mini-transcribe",
            file: audioFile,
            // optional:
            // language: "uk", // ÑÐºÑ‰Ð¾ Ñ…Ð¾Ñ‡ÐµÑˆ ÑÐ²Ð½Ð¾ Ð²ÐºÐ°Ð·Ð°Ñ‚Ð¸
        });

        const text = transcription.text;
        console.log("Transcribed text:", text);

        // 2) ÐšÐ¸Ð´Ð°Ñ”Ð¼Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð² Ñ‚Ð²Ñ–Ð¹ LifeMD Ð°Ð³ÐµÐ½Ñ‚
        const answer = await runLifeMdAgent(text);

        // 3) ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ”Ð¼Ð¾ Ñ– Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ‚, Ñ– Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð°Ð³ÐµÐ½Ñ‚Ð°
        res.json({
            transcript: text,
            answer,
        });
    } catch (err) {
        console.error("Voice API error:", err);
        res.status(500).json({ error: "Voice processing failed" });
    }
});


const PORT = Number(process.env.PORT) || 8080;
app.listen(PORT, () => {
    console.log(`Proxy backend running on http://localhost:${PORT}`);
});
